{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets , transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transformss = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transformss)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transformss)\n",
    "trainloader = DataLoader(trainset, batch_size = 600, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(1,6,kernel_size=5,padding=0,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.MaxPool2d(2,stride=2), #dim=14*14\n",
    "            \n",
    "            nn.Conv2d(6,16,kernel_size=5,padding=0,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2,stride=2), #dim=6*6\n",
    "            \n",
    "            nn.Conv2d(16,32,kernel_size=3,padding=0,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "            \n",
    "        )\n",
    "        self.linear=nn.Sequential(\n",
    "            nn.Linear(32,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,image):\n",
    "        \n",
    "        output=self.conv(image)\n",
    "        output=output.view(output.size(0),-1)\n",
    "        output=self.linear(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def ret_Image(self,image):\n",
    "        \n",
    "        output=self.conv(image)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn,iterations,optimizer,loss_fn,trainloader):\n",
    "    cnn.train()\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        lossperiter=0.0\n",
    "        \n",
    "        for j, data in enumerate(trainloader):\n",
    "            \n",
    "            img,label=data\n",
    "            \n",
    "            img=img.cuda()\n",
    "            label=label.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output=cnn(img)\n",
    "            loss=loss_fn(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lossperiter+=loss.item()\n",
    "        \n",
    "        print(lossperiter/600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(testloader,cnn,optimizer,lossfunction):\n",
    "    cnn.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    with  torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "\n",
    "            images,labels=data\n",
    "\n",
    "            images=images.cuda()\n",
    "\n",
    "\n",
    "            #calculate the output for each image\n",
    "            output = cnn(images)\n",
    "            #find the loss\n",
    "            pred = output.detach().cpu().max(1)[1]\n",
    "            total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "    avg_loss /= len(testset)\n",
    "    print('Accuracy '+ str((float(total_correct)*100) / len(testset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn=Net()\n",
    "iterations=10\n",
    "optimizer=optim.SGD(cnn.parameters(),lr=0.08)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "cnn.cuda()\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3709585110346476\n",
      "0.3392715577284495\n",
      "0.32131367246309916\n",
      "0.3071698699394862\n",
      "0.2979565093914668\n",
      "0.2942353105545044\n",
      "0.2921982479095459\n",
      "0.29100979804992677\n",
      "0.2898919222752253\n",
      "0.28886417965094247\n"
     ]
    }
   ],
   "source": [
    "train(cnn,iterations,optimizer,loss_fn,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 71.76\n"
     ]
    }
   ],
   "source": [
    "test_network(testloader,cnn,optimizer,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_heatmap(testloader,cnn):\n",
    "    cnn.eval()\n",
    "    counter=0\n",
    "    for i,data in enumerate(testloader):\n",
    "\n",
    "        images,_=data\n",
    "        images=images.cuda()\n",
    "        \"\"\"img = cv2.imread('images', 1)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\"\"\"\n",
    "        output=cnn.ret_Image(images)\n",
    "        output=output.detach().cpu().squeeze(dim=0)\n",
    "        \n",
    "        img=getUpsampled(output)\n",
    "        \n",
    "        while(counter<5):\n",
    "            plt.imshow(img)\n",
    "            counter+=1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUpsampled(output):\n",
    "        \n",
    "    m = Upsample(scale_factor=28, mode='bilinear')\n",
    "    output_upsampled = m(output)\n",
    "    output_upsampled = output_upsampled.view(output_upsampled.shape[1], output_upsampled.shape[2], output_upsampled.shape[0])\n",
    "    \n",
    "    return output_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 28, 64]' is invalid for input of size 1605632",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9ea057253a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-878c95547b83>\u001b[0m in \u001b[0;36mtest_heatmap\u001b[1;34m(testloader, cnn)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetUpsampled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-0bb91c84db31>\u001b[0m in \u001b[0;36mgetUpsampled\u001b[1;34m(output)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moutput_upsampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutput_upsampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_upsampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_upsampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_upsampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_upsampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput_upsampled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[32, 28, 64]' is invalid for input of size 1605632"
     ]
    }
   ],
   "source": [
    "from  torch.nn.modules.upsampling import Upsample\n",
    "\n",
    "test_heatmap(testloader,cnn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
